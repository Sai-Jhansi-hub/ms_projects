{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"14waohc6SvTW0nlD_zvmEk7-GRUMqqFc8","timestamp":1685829782614},{"file_id":"1aF_rg1FQm5SmVsWCXGguUCXUfczKyfJf","timestamp":1685644018269},{"file_id":"1Szn1SZhTfsjIfI7oCBOXs1vTNdlrE9Cg","timestamp":1684533351470},{"file_id":"1svlNYF5QH1EJIgkawf93orW542NVULnw","timestamp":1684502207864},{"file_id":"1eaW9w6Bqlo3AZxLuBUy7N4_dPys3Y5wO","timestamp":1625171335275},{"file_id":"1jAaByZ3kJhK2yl3XbMUAAhghVXWdLMEB","timestamp":1601323874115},{"file_id":"https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/shallow_net_in_keras.ipynb","timestamp":1597241020449}],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Whf_8TEO-6qX"},"source":["# CAP 6619 - Deep Learning - Dr Marques\n","## Project 1\n","## Image Classifiers Using Neural Networks and the MNIST and Fashion MNIST Datasets"]},{"cell_type":"markdown","source":["Sai Jhansi Kongara\n","\n","\n","https://colab.research.google.com/drive/14waohc6SvTW0nlD_zvmEk7-GRUMqqFc8?usp=sharing"],"metadata":{"id":"dOGJOhMgmu4o"}},{"cell_type":"markdown","metadata":{"id":"32AXUOrLxvoD"},"source":["Useful references and sources:\n","\n","**MNIST**\n","\n","- https://www.tensorflow.org/datasets/catalog/mnist\n","\n","- https://en.wikipedia.org/wiki/MNIST_database\n","\n","- https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/shallow_net_in_keras.ipynb\n","\n","**Fashion MNIST**\n","\n","- https://www.tensorflow.org/datasets/catalog/fashion_mnist\n","\n","- https://en.wikipedia.org/wiki/Fashion_MNIST\n","\n","- https://keras.io/api/datasets/fashion_mnist/"]},{"cell_type":"markdown","metadata":{"id":"BEn1cfWJ-6rH"},"source":["## PART 1 - *MNIST classifier using MLP*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2u-hfaHC-6qb"},"source":["### Import Needed Resources / Libraries"]},{"cell_type":"code","metadata":{"id":"1H7CSr4a-6qb"},"source":["from tensorflow import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","\n","from keras import layers\n","\n","from matplotlib import pyplot as plt\n","\n","import numpy as np\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxNd2jV5-6qg"},"source":["### Load and prepare the data"]},{"cell_type":"code","metadata":{"id":"AL5uSsG5EoEw"},"source":["# Model / data parameters\n","num_classes = 10\n","input_shape = (28, 28, 1)\n","\n","# the data, split between train and validation sets\n","(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Examine Data"],"metadata":{"id":"NUJlQmcuS1-b"}},{"cell_type":"code","metadata":{"id":"x2jsR31jEqYn"},"source":["X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOXe9zdD-6qp"},"source":["y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99XuEIZf-6qr"},"source":["y_train[0:12]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rcidoo4X-6qt"},"source":["plt.figure(figsize=(5,5))\n","for k in range(12):\n","    plt.subplot(3, 4, k+1)\n","    plt.imshow(X_train[k], cmap='Greys')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xL2vkR3jO2md"},"source":["X_valid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKtAwVhYO34o"},"source":["y_valid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rITLTiol7eZH"},"source":["y_valid[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7wsvxTt7iZO"},"source":["plt.imshow(X_valid[0], cmap='Greys')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKSraXzh-6qw"},"source":["# Reshape (flatten) images\n","X_train_reshaped = X_train.reshape(60000, 784).astype('float32')\n","X_valid_reshaped = X_valid.reshape(10000, 784).astype('float32')\n","\n","# Scale images to the [0, 1] range\n","X_train_scaled_reshaped = X_train_reshaped / 255\n","X_valid_scaled_reshaped = X_valid_reshaped / 255\n","\n","# Renaming for conciseness\n","X_training = X_train_scaled_reshaped\n","X_validation = X_valid_scaled_reshaped\n","\n","print(\"X_training shape (after reshaping + scaling):\", X_training.shape)\n","print(X_training.shape[0], \"train samples\")\n","print(\"X_validation shape (after reshaping + scaling):\", X_validation.shape)\n","print(X_validation.shape[0], \"validation samples\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amUBlLnG-6qz"},"source":["# convert class vectors to binary class matrices\n","y_training = keras.utils.to_categorical(y_train, num_classes)\n","y_validation = keras.utils.to_categorical(y_valid, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRX6auItPqtX"},"source":["print(y_valid[0])\n","print(y_validation[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eflqPyf9-6rW"},"source":["### Configure model"]},{"cell_type":"code","metadata":{"id":"r7CsGuzIKvZd"},"source":["model = Sequential()\n","model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n","model.add(Dense(10, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQTQzXvJ-6rJ"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0KPx8Di-6rO"},"source":["(64*784)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7KDBMCS-6rQ"},"source":["(64*784)+64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ls_u6Lne-6rU"},"source":["(10*64)+10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZxAxL41M-6rX"},"source":["model.compile(\n","    loss='mean_squared_error',\n","    optimizer=SGD(learning_rate=0.01),\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DId95CJ_-6rY"},"source":["### Train!"]},{"cell_type":"code","metadata":{"id":"OGws4yu8-6rZ"},"source":["batch_size=128\n","epochs=200\n","\n","history = model.fit(\n","  X_training, # training data\n","  y_training, # training targets\n","  epochs=epochs,\n","  batch_size=batch_size,\n","  verbose=1,\n","  validation_data=(X_validation, y_validation)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8AJ6owdTR1UA"},"source":["### Plot learning curves"]},{"cell_type":"code","metadata":{"id":"QF8qu8ByR314"},"source":["# list all data in history\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"763bQLbzQmw4"},"source":["### Evaluate the model"]},{"cell_type":"code","metadata":{"id":"2siGhXrm-6rb"},"source":["model.evaluate(X_validation, y_validation)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **PART 1** - *Your Turn*"],"metadata":{"id":"cFfmkCZ-N1lM"}},{"cell_type":"markdown","source":["### **Part 1 - Tasks:**  *(40 pts)*\n","1. Write code to display the confusion matrix for your classifier and comment on the insights such confusion matrix provides. See [this](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html) for an example.\n","\n","2. Write code to display 10 cases where the classifier makes mistakes. Make sure to display both the true value as well as the predicted value."],"metadata":{"id":"lRWMcw5HOJDr"}},{"cell_type":"markdown","source":["#### 1.a. Confusion Matrix *(10 pts)*"],"metadata":{"id":"eUQnhnk4bsuk"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Define the class names\n","classes_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6', 'Class 7', 'Class 8', 'Class 9']\n","\n","# Get predicted probabilities\n","y_pred_prob = model.predict(X_validation)\n","\n","# Convert probabilities to predicted labels\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(y_valid, y_pred)\n","# Display confusion matrix using a heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes_names, yticklabels=classes_names)\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.show()\n","\n","\n","\n"],"metadata":{"id":"zAtq58hePWPy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.b. Comment on the insights confusion matrix provides *(10 pts)*"],"metadata":{"id":"IPh2wMtAb00B"}},{"cell_type":"markdown","source":["The confusion matrix offers important insights into how well a categorization model performs. By contrasting the genuine labels from the validation set with the predicted labels, it provides a visual summary of the model's predictions. The confusion matrix can provide the following information:\n","True Positives (TP): In the confusion matrix, the diagonal elements represent the cases that were correctly categorized into each class. A greater value along the diagonal denotes more accurate forecasts.\n","False Negatives (FN) are the cases that were wrongly identified as belonging to a different class but actually fall within a specific class. The values in each row, omitting the diagonal element, reflect these examples. It shows how many examples for each class were either overlooked or wrongly categorized.\n","True Negatives (TN): The values outside of each class's diagonal and outside of its related rows and columns are accurately predicted cases that don't fall under the corresponding classes. The confusion matrix may occasionally not directly display the TN values.\n","You can learn a lot by studying the confusion matrix, including:\n","Overall Model Performance: By adding up the values on the diagonal and dividing it by the total number of instances, you can determine the model's overall accuracy. Performance is improved when the values along the diagonal are higher.\n","Performance per class: The confusion matrix enables you to assess the model's effectiveness in each specific class. By examining the numbers off the diagonal, you may determine which classes are more difficult for the model to appropriately categorize. It aids in determining whether the model tends to misclassify particular classes or if it excels at handling particular classes.\n","Unbalanced Classes: If the class distributions in the dataset are unbalanced, the confusion matrix may reveal potential problems. Instances from the majority class may be more likely to be misclassified by the model if, for instance, one class has a much higher number of instances than the others.\n","Error Patterns: By looking at the values that are off the diagonal, you can spot certain error patterns or class misunderstandings. It assists in identifying the classes that are commonly confused with one another and can offer suggestions for future model or dataset enhancements.\n","The confusion matrix is a useful tool for assessing the effectiveness of a classification model and learning about its advantages, disadvantages, and prospective areas for development.\n"],"metadata":{"id":"iN8Brv58b-RL"}},{"cell_type":"markdown","source":["#### 2.Display 10 cases where the classifier makes mistakes. *(20 pts)*"],"metadata":{"id":"w-3gs_uqcHll"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# Get predicted probabilities\n","y_pred_prob = model.predict(X_validation)\n","\n","# Convert probabilities to predicted labels\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","# Find indices where true labels and predicted labels don't match\n","incorrect_indices = np.where(y_valid != y_pred)[0]\n","\n","# Randomly select 10 incorrect predictions\n","incorrect_samples = np.random.choice(incorrect_indices, size=10, replace=False)\n","\n","# Display the true and predicted labels for the selected samples\n","plt.figure(figsize=(12, 8))\n","for i, sample_idx in enumerate(incorrect_samples):\n","    plt.subplot(2, 5, i+1)\n","    plt.imshow(X_valid[sample_idx], cmap='gray')\n","    plt.title(\"True: {}, Predicted: {}\".format(classes_names[y_valid[sample_idx]], classes_names[y_pred[sample_idx]]))\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()\n","\n","\n"],"metadata":{"id":"h2qgIuivcQpQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7O3lpDxUsmT"},"source":["## PART 2 - *Fashion MNIST*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lmobz-vfUsmu"},"source":["### Load and prepare the data"]},{"cell_type":"code","source":["# Model / data parameters\n","num_classes = 10\n","input_shape = [28 ,28]"],"metadata":{"id":"7tiUAea0YgGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading and Spliting Data in Test and Train\n","(X_train, y_train), (X_valid, y_valid) = tf.keras.datasets.fashion_mnist.load_data()\n","assert X_train.shape == (60000, 28, 28)\n","assert X_valid.shape == (10000, 28, 28)\n","assert y_train.shape == (60000,)\n","assert y_valid.shape == (10000,)"],"metadata":{"id":"9WuYpbzKVb52"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defining Classes"],"metadata":{"id":"SJLgwT4BVsXJ"}},{"cell_type":"code","source":["classes_names = ['T-shirt/top' ,  'Trouser' ,'Pullover' , 'Dress', 'Coat','Sandal','Shirt','Sneaker', 'Bag','Ankle Boot']"],"metadata":{"id":"_Vtsr209Vs7I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Examine Data"],"metadata":{"id":"mk5jfFGpUsm4"}},{"cell_type":"code","metadata":{"id":"bqDnQHxBUsmv"},"source":["X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3-vq-ddUsmw"},"source":["y_valid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bm5DzZ5Usmx"},"source":["y_train[0:12]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBSF0061Usmy"},"source":["plt.figure(figsize=(5,5))\n","for k in range(12):\n","    plt.subplot(3, 4, k+1)\n","    plt.imshow(X_train[k], cmap='Greys')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ZFhStimUsmz"},"source":["X_valid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkcVKlIdUsm0"},"source":["y_valid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2pxEjaSUsm0"},"source":["y_valid[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBxa15BlUsm1"},"source":["plt.imshow(X_valid[0], cmap='Greys')\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reshape (flatten) images\n","X_train_reshaped = X_train.reshape(60000, 784).astype('float32')\n","X_valid_reshaped = X_valid.reshape(10000, 784).astype('float32')\n","\n","# Scale images to the [0, 1] range\n","X_train_scaled_reshaped = X_train_reshaped / 255\n","X_valid_scaled_reshaped = X_valid_reshaped / 255\n","\n","# Renaming for conciseness\n","X_training = X_train_scaled_reshaped\n","X_validation = X_valid_scaled_reshaped\n","\n","print(\"X_training shape (after reshaping + scaling):\", X_training.shape)\n","print(X_training.shape[0], \"train samples\")\n","print(\"X_validation shape (after reshaping + scaling):\", X_validation.shape)\n","print(X_validation.shape[0], \"validation samples\")"],"metadata":{"id":"Y1uqe2qNvzTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j77kPrf9Usm3"},"source":["# convert class vectors to binary class matrices\n","y_training = keras.utils.to_categorical(y_train, num_classes)\n","y_validation = keras.utils.to_categorical(y_valid, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7K4nOvY8Usm3"},"source":["print(y_valid[0])\n","print(y_validation[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **PART 2** - *Your Turn*"],"metadata":{"id":"tTPfK-zFOAfi"}},{"cell_type":"markdown","source":["### **Part 2 - Tasks:** *(60 pts)*\n","Build a NN solution identical to the one before: *(20 pts)*\n","> a. Plot learning curves *(10 pts)*\n","\n","> b. Display the confusion matrix for your classifier *(10 pts)*\n","\n","> c. Evaluate the model, identify accuracy, etc. *(10 pts)*\n","\n","> d. Discuss why the results are not as good. *(10 pts)*\n","\n","\n","\n"],"metadata":{"id":"37Jfa71GO-o3"}},{"cell_type":"markdown","source":["#### NN solution *(20 pts)*"],"metadata":{"id":"wfynsAmuRHhR"}},{"cell_type":"markdown","source":["Configure the Model *(10 pts)*"],"metadata":{"id":"0S1JKBzLkHCq"}},{"cell_type":"code","source":["# Your Configure the Model code here and in additional code cells as needed\n","# use same model and hyperparameters as was used for MNIST above\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","\n","# Model configuration\n","num_classes = 10\n","input_shape = (784,)\n","\n","# Build the model\n","model = Sequential()\n","model.add(Dense(64, activation='sigmoid', input_shape=input_shape))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","# Configure the model\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=SGD(learning_rate=0.01),\n","    metrics=['accuracy']\n",")\n","\n"],"metadata":{"id":"ebaDH_ltkQ4K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the Model  *(10 pts)*"],"metadata":{"id":"0wVjOdUhkETu"}},{"cell_type":"code","source":["# Your Train the Model code here and in additional code cells as needed\n","# same as was used in MNIST above\n","# Train the model\n","batch_size = 128\n","epochs = 200\n","history = model.fit(\n","    X_training,\n","    y_training,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    verbose=1,\n","    validation_data=(X_validation, y_validation)\n",")\n"],"metadata":{"id":"r265wxucPLZQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d7eaa34-3c76-46b0-de37-699c44a9dfb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 2s 4ms/step - loss: 1.8962 - accuracy: 0.5388 - val_loss: 1.5647 - val_accuracy: 0.6896\n","Epoch 2/200\n","469/469 [==============================] - 2s 3ms/step - loss: 1.3661 - accuracy: 0.7024 - val_loss: 1.2171 - val_accuracy: 0.7142\n","Epoch 3/200\n","469/469 [==============================] - 1s 3ms/step - loss: 1.1106 - accuracy: 0.7202 - val_loss: 1.0353 - val_accuracy: 0.7197\n","Epoch 4/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.9677 - accuracy: 0.7308 - val_loss: 0.9267 - val_accuracy: 0.7283\n","Epoch 5/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.8778 - accuracy: 0.7402 - val_loss: 0.8547 - val_accuracy: 0.7342\n","Epoch 6/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.8164 - accuracy: 0.7480 - val_loss: 0.8041 - val_accuracy: 0.7400\n","Epoch 7/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.7714 - accuracy: 0.7540 - val_loss: 0.7660 - val_accuracy: 0.7484\n","Epoch 8/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.7369 - accuracy: 0.7599 - val_loss: 0.7363 - val_accuracy: 0.7551\n","Epoch 9/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.7092 - accuracy: 0.7656 - val_loss: 0.7116 - val_accuracy: 0.7596\n","Epoch 10/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.7704 - val_loss: 0.6916 - val_accuracy: 0.7647\n","Epoch 11/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.6669 - accuracy: 0.7757 - val_loss: 0.6741 - val_accuracy: 0.7690\n","Epoch 12/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6500 - accuracy: 0.7800 - val_loss: 0.6591 - val_accuracy: 0.7744\n","Epoch 13/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.7846 - val_loss: 0.6454 - val_accuracy: 0.7777\n","Epoch 14/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6219 - accuracy: 0.7885 - val_loss: 0.6335 - val_accuracy: 0.7797\n","Epoch 15/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.6099 - accuracy: 0.7926 - val_loss: 0.6226 - val_accuracy: 0.7852\n","Epoch 16/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5989 - accuracy: 0.7962 - val_loss: 0.6125 - val_accuracy: 0.7886\n","Epoch 17/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5888 - accuracy: 0.7994 - val_loss: 0.6032 - val_accuracy: 0.7899\n","Epoch 18/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5797 - accuracy: 0.8028 - val_loss: 0.5952 - val_accuracy: 0.7938\n","Epoch 19/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5712 - accuracy: 0.8063 - val_loss: 0.5869 - val_accuracy: 0.7961\n","Epoch 20/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.8090 - val_loss: 0.5802 - val_accuracy: 0.7991\n","Epoch 21/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5561 - accuracy: 0.8107 - val_loss: 0.5731 - val_accuracy: 0.8012\n","Epoch 22/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5494 - accuracy: 0.8131 - val_loss: 0.5674 - val_accuracy: 0.8023\n","Epoch 23/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5431 - accuracy: 0.8149 - val_loss: 0.5616 - val_accuracy: 0.8046\n","Epoch 24/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.8166 - val_loss: 0.5561 - val_accuracy: 0.8054\n","Epoch 25/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.8178 - val_loss: 0.5514 - val_accuracy: 0.8068\n","Epoch 26/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.8193 - val_loss: 0.5464 - val_accuracy: 0.8082\n","Epoch 27/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5217 - accuracy: 0.8212 - val_loss: 0.5420 - val_accuracy: 0.8096\n","Epoch 28/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5171 - accuracy: 0.8223 - val_loss: 0.5381 - val_accuracy: 0.8115\n","Epoch 29/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5126 - accuracy: 0.8241 - val_loss: 0.5348 - val_accuracy: 0.8114\n","Epoch 30/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5087 - accuracy: 0.8249 - val_loss: 0.5305 - val_accuracy: 0.8128\n","Epoch 31/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5048 - accuracy: 0.8266 - val_loss: 0.5267 - val_accuracy: 0.8145\n","Epoch 32/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5012 - accuracy: 0.8271 - val_loss: 0.5238 - val_accuracy: 0.8151\n","Epoch 33/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4977 - accuracy: 0.8278 - val_loss: 0.5205 - val_accuracy: 0.8153\n","Epoch 34/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4944 - accuracy: 0.8287 - val_loss: 0.5180 - val_accuracy: 0.8171\n","Epoch 35/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.8301 - val_loss: 0.5147 - val_accuracy: 0.8179\n","Epoch 36/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.8309 - val_loss: 0.5119 - val_accuracy: 0.8184\n","Epoch 37/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4853 - accuracy: 0.8316 - val_loss: 0.5096 - val_accuracy: 0.8186\n","Epoch 38/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4826 - accuracy: 0.8326 - val_loss: 0.5069 - val_accuracy: 0.8202\n","Epoch 39/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4799 - accuracy: 0.8328 - val_loss: 0.5047 - val_accuracy: 0.8208\n","Epoch 40/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.8340 - val_loss: 0.5023 - val_accuracy: 0.8215\n","Epoch 41/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4749 - accuracy: 0.8341 - val_loss: 0.5001 - val_accuracy: 0.8221\n","Epoch 42/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4725 - accuracy: 0.8353 - val_loss: 0.4986 - val_accuracy: 0.8239\n","Epoch 43/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4703 - accuracy: 0.8364 - val_loss: 0.4961 - val_accuracy: 0.8235\n","Epoch 44/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4680 - accuracy: 0.8366 - val_loss: 0.4942 - val_accuracy: 0.8246\n","Epoch 45/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4659 - accuracy: 0.8373 - val_loss: 0.4927 - val_accuracy: 0.8243\n","Epoch 46/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4638 - accuracy: 0.8373 - val_loss: 0.4907 - val_accuracy: 0.8247\n","Epoch 47/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4619 - accuracy: 0.8385 - val_loss: 0.4890 - val_accuracy: 0.8262\n","Epoch 48/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.8388 - val_loss: 0.4875 - val_accuracy: 0.8260\n","Epoch 49/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.8398 - val_loss: 0.4858 - val_accuracy: 0.8271\n","Epoch 50/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8402 - val_loss: 0.4841 - val_accuracy: 0.8274\n","Epoch 51/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4543 - accuracy: 0.8407 - val_loss: 0.4823 - val_accuracy: 0.8275\n","Epoch 52/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4527 - accuracy: 0.8413 - val_loss: 0.4813 - val_accuracy: 0.8281\n","Epoch 53/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4511 - accuracy: 0.8417 - val_loss: 0.4797 - val_accuracy: 0.8283\n","Epoch 54/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.8424 - val_loss: 0.4782 - val_accuracy: 0.8290\n","Epoch 55/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8431 - val_loss: 0.4767 - val_accuracy: 0.8290\n","Epoch 56/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4464 - accuracy: 0.8435 - val_loss: 0.4753 - val_accuracy: 0.8297\n","Epoch 57/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4448 - accuracy: 0.8444 - val_loss: 0.4743 - val_accuracy: 0.8292\n","Epoch 58/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4434 - accuracy: 0.8444 - val_loss: 0.4729 - val_accuracy: 0.8297\n","Epoch 59/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4419 - accuracy: 0.8448 - val_loss: 0.4718 - val_accuracy: 0.8309\n","Epoch 60/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4406 - accuracy: 0.8454 - val_loss: 0.4710 - val_accuracy: 0.8305\n","Epoch 61/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4392 - accuracy: 0.8457 - val_loss: 0.4695 - val_accuracy: 0.8315\n","Epoch 62/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4379 - accuracy: 0.8467 - val_loss: 0.4683 - val_accuracy: 0.8315\n","Epoch 63/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.8469 - val_loss: 0.4675 - val_accuracy: 0.8323\n","Epoch 64/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4353 - accuracy: 0.8469 - val_loss: 0.4661 - val_accuracy: 0.8317\n","Epoch 65/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.8477 - val_loss: 0.4648 - val_accuracy: 0.8322\n","Epoch 66/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8475 - val_loss: 0.4639 - val_accuracy: 0.8327\n","Epoch 67/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4317 - accuracy: 0.8484 - val_loss: 0.4630 - val_accuracy: 0.8341\n","Epoch 68/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4305 - accuracy: 0.8485 - val_loss: 0.4619 - val_accuracy: 0.8334\n","Epoch 69/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4293 - accuracy: 0.8492 - val_loss: 0.4615 - val_accuracy: 0.8348\n","Epoch 70/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4283 - accuracy: 0.8491 - val_loss: 0.4607 - val_accuracy: 0.8349\n","Epoch 71/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4272 - accuracy: 0.8494 - val_loss: 0.4590 - val_accuracy: 0.8352\n","Epoch 72/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4261 - accuracy: 0.8497 - val_loss: 0.4582 - val_accuracy: 0.8349\n","Epoch 73/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8503 - val_loss: 0.4574 - val_accuracy: 0.8351\n","Epoch 74/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4240 - accuracy: 0.8508 - val_loss: 0.4566 - val_accuracy: 0.8364\n","Epoch 75/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4230 - accuracy: 0.8508 - val_loss: 0.4555 - val_accuracy: 0.8365\n","Epoch 76/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4220 - accuracy: 0.8511 - val_loss: 0.4545 - val_accuracy: 0.8366\n","Epoch 77/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4209 - accuracy: 0.8519 - val_loss: 0.4537 - val_accuracy: 0.8369\n","Epoch 78/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4201 - accuracy: 0.8517 - val_loss: 0.4532 - val_accuracy: 0.8371\n","Epoch 79/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4191 - accuracy: 0.8520 - val_loss: 0.4523 - val_accuracy: 0.8380\n","Epoch 80/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4181 - accuracy: 0.8525 - val_loss: 0.4513 - val_accuracy: 0.8383\n","Epoch 81/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8529 - val_loss: 0.4509 - val_accuracy: 0.8378\n","Epoch 82/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4163 - accuracy: 0.8530 - val_loss: 0.4499 - val_accuracy: 0.8386\n","Epoch 83/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4155 - accuracy: 0.8538 - val_loss: 0.4493 - val_accuracy: 0.8394\n","Epoch 84/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4146 - accuracy: 0.8536 - val_loss: 0.4488 - val_accuracy: 0.8401\n","Epoch 85/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8547 - val_loss: 0.4478 - val_accuracy: 0.8385\n","Epoch 86/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.8542 - val_loss: 0.4469 - val_accuracy: 0.8398\n","Epoch 87/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4120 - accuracy: 0.8548 - val_loss: 0.4461 - val_accuracy: 0.8406\n","Epoch 88/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4111 - accuracy: 0.8548 - val_loss: 0.4456 - val_accuracy: 0.8402\n","Epoch 89/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8552 - val_loss: 0.4448 - val_accuracy: 0.8415\n","Epoch 90/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4095 - accuracy: 0.8558 - val_loss: 0.4441 - val_accuracy: 0.8419\n","Epoch 91/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4088 - accuracy: 0.8556 - val_loss: 0.4435 - val_accuracy: 0.8424\n","Epoch 92/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4080 - accuracy: 0.8561 - val_loss: 0.4430 - val_accuracy: 0.8427\n","Epoch 93/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4072 - accuracy: 0.8564 - val_loss: 0.4423 - val_accuracy: 0.8410\n","Epoch 94/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.8565 - val_loss: 0.4415 - val_accuracy: 0.8419\n","Epoch 95/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4057 - accuracy: 0.8564 - val_loss: 0.4409 - val_accuracy: 0.8430\n","Epoch 96/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8570 - val_loss: 0.4405 - val_accuracy: 0.8427\n","Epoch 97/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8568 - val_loss: 0.4402 - val_accuracy: 0.8417\n","Epoch 98/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4036 - accuracy: 0.8577 - val_loss: 0.4389 - val_accuracy: 0.8430\n","Epoch 99/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4028 - accuracy: 0.8580 - val_loss: 0.4386 - val_accuracy: 0.8443\n","Epoch 100/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8579 - val_loss: 0.4378 - val_accuracy: 0.8437\n","Epoch 101/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4014 - accuracy: 0.8579 - val_loss: 0.4377 - val_accuracy: 0.8433\n","Epoch 102/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4007 - accuracy: 0.8584 - val_loss: 0.4371 - val_accuracy: 0.8444\n","Epoch 103/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4001 - accuracy: 0.8584 - val_loss: 0.4360 - val_accuracy: 0.8441\n","Epoch 104/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3994 - accuracy: 0.8590 - val_loss: 0.4354 - val_accuracy: 0.8447\n","Epoch 105/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8594 - val_loss: 0.4351 - val_accuracy: 0.8452\n","Epoch 106/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3980 - accuracy: 0.8595 - val_loss: 0.4346 - val_accuracy: 0.8460\n","Epoch 107/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3974 - accuracy: 0.8602 - val_loss: 0.4341 - val_accuracy: 0.8454\n","Epoch 108/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3968 - accuracy: 0.8598 - val_loss: 0.4334 - val_accuracy: 0.8463\n","Epoch 109/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8601 - val_loss: 0.4333 - val_accuracy: 0.8454\n","Epoch 110/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3955 - accuracy: 0.8604 - val_loss: 0.4322 - val_accuracy: 0.8467\n","Epoch 111/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3949 - accuracy: 0.8608 - val_loss: 0.4319 - val_accuracy: 0.8461\n","Epoch 112/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3942 - accuracy: 0.8609 - val_loss: 0.4315 - val_accuracy: 0.8471\n","Epoch 113/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3938 - accuracy: 0.8609 - val_loss: 0.4309 - val_accuracy: 0.8468\n","Epoch 114/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3931 - accuracy: 0.8611 - val_loss: 0.4303 - val_accuracy: 0.8470\n","Epoch 115/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3925 - accuracy: 0.8613 - val_loss: 0.4299 - val_accuracy: 0.8465\n","Epoch 116/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3919 - accuracy: 0.8615 - val_loss: 0.4293 - val_accuracy: 0.8473\n","Epoch 117/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3914 - accuracy: 0.8613 - val_loss: 0.4287 - val_accuracy: 0.8473\n","Epoch 118/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3907 - accuracy: 0.8616 - val_loss: 0.4284 - val_accuracy: 0.8476\n","Epoch 119/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3902 - accuracy: 0.8622 - val_loss: 0.4277 - val_accuracy: 0.8476\n","Epoch 120/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3896 - accuracy: 0.8622 - val_loss: 0.4274 - val_accuracy: 0.8484\n","Epoch 121/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3891 - accuracy: 0.8623 - val_loss: 0.4269 - val_accuracy: 0.8481\n","Epoch 122/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3886 - accuracy: 0.8623 - val_loss: 0.4263 - val_accuracy: 0.8490\n","Epoch 123/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3880 - accuracy: 0.8625 - val_loss: 0.4259 - val_accuracy: 0.8492\n","Epoch 124/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3875 - accuracy: 0.8629 - val_loss: 0.4257 - val_accuracy: 0.8480\n","Epoch 125/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.8625 - val_loss: 0.4252 - val_accuracy: 0.8484\n","Epoch 126/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3864 - accuracy: 0.8635 - val_loss: 0.4248 - val_accuracy: 0.8498\n","Epoch 127/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3858 - accuracy: 0.8638 - val_loss: 0.4240 - val_accuracy: 0.8499\n","Epoch 128/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3853 - accuracy: 0.8634 - val_loss: 0.4235 - val_accuracy: 0.8497\n","Epoch 129/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3848 - accuracy: 0.8636 - val_loss: 0.4233 - val_accuracy: 0.8504\n","Epoch 130/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3842 - accuracy: 0.8641 - val_loss: 0.4231 - val_accuracy: 0.8493\n","Epoch 131/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3838 - accuracy: 0.8642 - val_loss: 0.4229 - val_accuracy: 0.8494\n","Epoch 132/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3833 - accuracy: 0.8644 - val_loss: 0.4223 - val_accuracy: 0.8497\n","Epoch 133/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3827 - accuracy: 0.8644 - val_loss: 0.4215 - val_accuracy: 0.8509\n","Epoch 134/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3822 - accuracy: 0.8643 - val_loss: 0.4215 - val_accuracy: 0.8496\n","Epoch 135/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3818 - accuracy: 0.8645 - val_loss: 0.4205 - val_accuracy: 0.8510\n","Epoch 136/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3812 - accuracy: 0.8651 - val_loss: 0.4208 - val_accuracy: 0.8503\n","Epoch 137/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3808 - accuracy: 0.8648 - val_loss: 0.4198 - val_accuracy: 0.8508\n","Epoch 138/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3804 - accuracy: 0.8646 - val_loss: 0.4197 - val_accuracy: 0.8512\n","Epoch 139/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3799 - accuracy: 0.8650 - val_loss: 0.4192 - val_accuracy: 0.8500\n","Epoch 140/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3793 - accuracy: 0.8655 - val_loss: 0.4189 - val_accuracy: 0.8515\n","Epoch 141/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3789 - accuracy: 0.8657 - val_loss: 0.4183 - val_accuracy: 0.8505\n","Epoch 142/200\n","465/469 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8662"]}]},{"cell_type":"markdown","source":["#### Plot learning curves *(10 pts)*"],"metadata":{"id":"4WJQiEh4RXEH"}},{"cell_type":"code","source":["# Plot learning curves\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n"],"metadata":{"id":"M-TWkVPHRXEl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Display the confusion matrix for your classifier *(10 pts)*"],"metadata":{"id":"CGjUQY-oRXlX"}},{"cell_type":"code","source":["# Your confusion matrix code here and in additional code cells as needed\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","# Define the class names\n","classes_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6', 'Class 7', 'Class 8', 'Class 9']\n","\n","# Get predicted labels\n","y_pred = np.argmax(model.predict(X_validation), axis=-1)\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(y_valid, y_pred)\n","\n","# Display confusion matrix using a heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes_names, yticklabels=classes_names)\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.show()\n","\n"],"metadata":{"id":"KgLleoqYRXlX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Evaluate the model, identify accuracy, etc. *(10 pts)*"],"metadata":{"id":"4__FfaTFRlNh"}},{"cell_type":"code","source":["# Your Evaluate the model code here and in additional code cells as needed\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_validation, y_validation)\n","\n","# Print the accuracy\n","print(\"Accuracy:\", accuracy)\n","\n"],"metadata":{"id":"PZCY7q7ORlN4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Discuss why the results are not as good.\n","\n","If you had more time what would you do to improve the results? *(10 pts)*"],"metadata":{"id":"Os2Av7zxRmFF"}},{"cell_type":"markdown","source":["There may be a number of factors to consider if the results are not what was anticipated.\n","\n","Low accuracy may result from the model's inability to understand enough patterns and changes in the data if it was trained on a tiny dataset.\n","\n","\n","Overfitting: When a model learns to perform well on training data but is unable to generalize to novel, untried data, overfitting has taken place. Overfitting can be decreased by using regularization techniques like dropout or weight decay.\n","\n","Model complexity: A too-simple model could have trouble capturing intricate data patterns. Performance can be enhanced by expanding the model's capacity or applying more sophisticated topologies.\n","\n","Fine-tuning:The performance of the model may be greatly affected by hyperparameters like learning rate, batch size, or optimizer selection.\n","\n","If I had additional time to enhance the outcomes, I would think about taking the following actions:\n","\n","Data augmentation: Produce more training examples by randomly rotating, translating, scaling, or flipping the original data. The training set's diversity and variability can be increased with the use of data augmentation, which will boost generalization.\n","\n","Utilize the diversity of predictions by combining different models, either through bagging or boosting methods, to potentially improve performance.\n","\n","Use pre-trained models—such as those developed using extensive picture datasets like ImageNet—and fine-tune them for the particular task at hand. Utilizing the knowledge and representations acquired from one activity to enhance performance on another related task is known as transfer learning. To avoid overfitting and enhance generalization, use regularization techniques like dropout, L1 or L2 regularization, or batch normalization.\n","\n","Investigate various model designs or turn to automated methods like neural architecture search (NAS) to find better network topologies adapted to the given dataset and issue.\n","\n","Cross-validation: Use cross-validation to determine the model's performance with greater accuracy and to identify any potential problems, such as overfitting or data leakage.\n","\n","Examining misclassified samples and analyzing the model's predictions will help you find any patterns, biases, or places where the model falls short. This analysis may serve as a roadmap for future model or data preparation enhancements.\n","\n","Deploy the model in the actual world and monitor it there while gathering feedback from users or other systems using it. Analyze forecasts, keep an eye on the model's performance, and make adjustments depending on feedback from the real world.\n","\n","It is feasible to enhance the outcomes and create a model that is more reliable and accurate by addressing these factors.\n","\n","[ ]\n","# (OPTIONAL) Additional code to demonstrate possible improvements to the model in Part 2.\n"],"metadata":{"id":"dmNB2iVJRuXx"}},{"cell_type":"code","source":["# (OPTIONAL) Additional code to demonstrate possible improvements to the model in Part 2."],"metadata":{"id":"8vbWpIQPP7_b"},"execution_count":null,"outputs":[]}]}